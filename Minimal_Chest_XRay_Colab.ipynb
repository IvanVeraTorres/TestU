{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3bbb2d2c",
   "metadata": {},
   "source": [
    "\n",
    "# ü©∫ Proyecto Minimal: Neumon√≠a en Radiograf√≠as de T√≥rax (Colab)\n",
    "**Objetivo:** Entrenar un clasificador binario (NORMAL vs PNEUMONIA) con **EfficientNetB0** usando Google Colab, reportar m√©tricas clave y dejar el c√≥digo listo para subir a GitHub.\n",
    "\n",
    "> Uso acad√©mico. No es un sistema de diagn√≥stico m√©dico.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425a6520",
   "metadata": {},
   "source": [
    "\n",
    "## 1) Setup r√°pido\n",
    "Instala y verifica dependencias m√≠nimas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d51b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!pip -q install kaggle opencv-python-headless\n",
    "\n",
    "import os, numpy as np, tensorflow as tf, matplotlib.pyplot as plt, random\n",
    "SEED = 123; random.seed(SEED); np.random.seed(SEED); tf.random.set_seed(SEED)\n",
    "IMG_SIZE=(224,224); BATCH=32\n",
    "\n",
    "print(\"TF:\", tf.__version__)\n",
    "print(\"GPU:\", tf.config.list_physical_devices('GPU'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc6300a",
   "metadata": {},
   "source": [
    "\n",
    "## 2) Dataset (Kaggle)\n",
    "Sube tu `kaggle.json` (Kaggle ‚Üí Profile ‚Üí Account ‚Üí *Create New API Token*). Se descarga **Chest X-Ray Images (Pneumonia)**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3cd0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from google.colab import files, userdata\n",
    "import pathlib\n",
    "\n",
    "print(\"Sube tu kaggle.json\")\n",
    "uploaded = files.upload()\n",
    "pathlib.Path(\"/root/.kaggle\").mkdir(parents=True, exist_ok=True)\n",
    "with open(\"/root/.kaggle/kaggle.json\",\"wb\") as f: f.write(uploaded[\"kaggle.json\"])\n",
    "!chmod 600 /root/.kaggle/kaggle.json\n",
    "\n",
    "!kaggle datasets download -d paultimothymooney/chest-xray-pneumonia -p /content -q\n",
    "!unzip -q /content/chest-xray-pneumonia.zip -d /content\n",
    "DATA_DIR=\"/content/chest_xray\"\n",
    "print(\"OK. Carpetas:\", os.listdir(DATA_DIR))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c1c34b",
   "metadata": {},
   "source": [
    "\n",
    "## 3) Carga de datos y aumentaci√≥n\n",
    "Usamos `tf.data` y un pipeline simple con aumentaci√≥n ligera.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4906e102",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory as ds_from_dir\n",
    "\n",
    "train_ds = ds_from_dir(f\"{DATA_DIR}/train\", label_mode=\"binary\", image_size=IMG_SIZE, batch_size=BATCH, seed=SEED)\n",
    "val_ds   = ds_from_dir(f\"{DATA_DIR}/val\",   label_mode=\"binary\", image_size=IMG_SIZE, batch_size=BATCH, seed=SEED)\n",
    "test_ds  = ds_from_dir(f\"{DATA_DIR}/test\",  label_mode=\"binary\", image_size=IMG_SIZE, batch_size=BATCH, shuffle=False)\n",
    "\n",
    "AUTOTUNE=tf.data.AUTOTUNE\n",
    "train_ds=train_ds.shuffle(1024,seed=SEED).prefetch(AUTOTUNE)\n",
    "val_ds=val_ds.prefetch(AUTOTUNE); test_ds=test_ds.prefetch(AUTOTUNE)\n",
    "\n",
    "data_aug=tf.keras.Sequential([\n",
    "  tf.keras.layers.RandomFlip(\"horizontal\"),\n",
    "  tf.keras.layers.RandomRotation(0.05),\n",
    "  tf.keras.layers.RandomZoom(0.05),\n",
    "])\n",
    "CLASSES=[\"NORMAL\",\"PNEUMONIA\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f32c9fde",
   "metadata": {},
   "source": [
    "\n",
    "## 4) Modelo (EfficientNetB0) + Entrenamiento breve\n",
    "Primero congelamos la base; luego un peque√±o *fine-tuning*.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fcdfaa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "base=tf.keras.applications.EfficientNetB0(include_top=False, weights=\"imagenet\", input_shape=IMG_SIZE+(3,))\n",
    "base.trainable=False\n",
    "\n",
    "inp=layers.Input(IMG_SIZE+(3,))\n",
    "x=tf.keras.applications.efficientnet.preprocess_input(inp)\n",
    "x=data_aug(x); x=base(x, training=False)\n",
    "x=layers.GlobalAveragePooling2D()(x)\n",
    "x=layers.Dropout(0.25)(x)\n",
    "out=layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model=models.Model(inp,out)\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(1e-3), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "es=tf.keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True, monitor=\"val_loss\")\n",
    "ck=tf.keras.callbacks.ModelCheckpoint(\"best.keras\", save_best_only=True, monitor=\"val_loss\")\n",
    "\n",
    "history=model.fit(train_ds, validation_data=val_ds, epochs=6, callbacks=[es,ck], verbose=1)\n",
    "\n",
    "# Fine-tuning corto\n",
    "base.trainable=True\n",
    "for L in base.layers[:-20]: L.trainable=False\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(1e-4), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "history_ft=model.fit(train_ds, validation_data=val_ds, epochs=6, callbacks=[es,ck], verbose=1)\n",
    "\n",
    "best=tf.keras.models.load_model(\"best.keras\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45bd45a",
   "metadata": {},
   "source": [
    "\n",
    "## 5) M√©tricas y gr√°ficos (test)\n",
    "Accuracy, Precision, Recall, F1, ROC-AUC; matriz de confusi√≥n y curva ROC.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad32401",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve, precision_recall_fscore_support\n",
    "import numpy as np, matplotlib.pyplot as plt\n",
    "\n",
    "y_true=np.concatenate([y.numpy().astype(int).ravel() for _,y in test_ds])\n",
    "y_prob=best.predict(test_ds, verbose=0).ravel()\n",
    "y_pred=(y_prob>=0.5).astype(int)\n",
    "\n",
    "acc=(y_pred==y_true).mean()\n",
    "prec, rec, f1, _=precision_recall_fscore_support(y_true,y_pred,average=\"binary\",zero_division=0)\n",
    "auc=roc_auc_score(y_true,y_prob)\n",
    "\n",
    "print(f\"Accuracy: {acc:.4f} | Precision: {prec:.4f} | Recall: {rec:.4f} | F1: {f1:.4f} | ROC-AUC: {auc:.4f}\")\n",
    "print(\"\\nReporte:\\n\", classification_report(y_true,y_pred,target_names=CLASSES))\n",
    "\n",
    "# Matriz de confusi√≥n\n",
    "cm=confusion_matrix(y_true,y_pred)\n",
    "plt.figure(); plt.imshow(cm); plt.title(\"Matriz de confusi√≥n\")\n",
    "plt.xticks([0,1],CLASSES); plt.yticks([0,1],CLASSES)\n",
    "for i in range(2):\n",
    "  for j in range(2):\n",
    "    plt.text(j,i,cm[i,j],ha=\"center\",va=\"center\")\n",
    "plt.xlabel(\"Predicci√≥n\"); plt.ylabel(\"Real\"); plt.grid(False); plt.show()\n",
    "\n",
    "# Curva ROC\n",
    "fpr,tpr,_=roc_curve(y_true,y_prob)\n",
    "plt.figure(); plt.plot(fpr,tpr,label=f\"AUC={auc:.3f}\")\n",
    "plt.plot([0,1],[0,1],'--'); plt.xlabel(\"FPR\"); plt.ylabel(\"TPR\"); plt.title(\"ROC\"); plt.legend(); plt.grid(True); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5c889e",
   "metadata": {},
   "source": [
    "\n",
    "## 6) Grad-CAM (una imagen)\n",
    "Mapa de activaci√≥n para interpretar la predicci√≥n.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c18e680",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf, numpy as np, cv2, matplotlib.pyplot as plt\n",
    "\n",
    "# Ubicar capa conv final dentro de la base\n",
    "def find_last_conv(model_base):\n",
    "  for L in reversed(model_base.layers):\n",
    "    if isinstance(L, tf.keras.layers.Conv2D): return L.name\n",
    "  return None\n",
    "\n",
    "base_layer = best.layers[2].name  # submodelo EfficientNet\n",
    "last_conv = find_last_conv(best.get_layer(base_layer))\n",
    "\n",
    "def gradcam(img_array, model, base_name, last_conv_name):\n",
    "  base = model.get_layer(base_name)\n",
    "  last_conv_layer = base.get_layer(last_conv_name)\n",
    "  gmodel=tf.keras.Model([model.inputs],[last_conv_layer.output, model.output])\n",
    "  with tf.GradientTape() as tape:\n",
    "    conv_out, preds = gmodel(img_array)\n",
    "    loss = preds[:,0]\n",
    "  grads = tape.gradient(loss, conv_out)\n",
    "  pooled = tf.reduce_mean(grads, axis=(0,1,2))\n",
    "  conv_out=conv_out[0]\n",
    "  heat=tf.reduce_sum(tf.multiply(pooled,conv_out),axis=-1)\n",
    "  heat=np.maximum(heat,0)/ (np.max(heat)+1e-8)\n",
    "  return heat.numpy()\n",
    "\n",
    "for imgs, labels in test_ds.take(1):\n",
    "  img=imgs[0:1]; true=int(labels[0].numpy())\n",
    "\n",
    "heat=gradcam(img,best,base_layer,last_conv)\n",
    "img_uint8=tf.image.resize(img, (224,224)).numpy()[0].astype(\"uint8\")\n",
    "heat_res=cv2.resize((heat*255).astype(\"uint8\"), (224,224))\n",
    "heat_color=cv2.applyColorMap(heat_res, cv2.COLORMAP_JET)\n",
    "superimposed=cv2.addWeighted(img_uint8,0.6,heat_color,0.4,0)\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.subplot(1,3,1); plt.imshow(img_uint8); plt.title(\"Imagen\"); plt.axis(\"off\")\n",
    "plt.subplot(1,3,2); plt.imshow(heat_res, cmap=\"jet\"); plt.title(\"Grad-CAM\"); plt.axis(\"off\")\n",
    "plt.subplot(1,3,3); plt.imshow(superimposed); plt.title(\"Superpuesta\"); plt.axis(\"off\")\n",
    "plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244374c8",
   "metadata": {},
   "source": [
    "\n",
    "## 7) Guardar artefactos\n",
    "Modelo y m√©tricas principales en archivos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8666ead6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd, numpy as np, os\n",
    "\n",
    "best.save(\"/content/model_minimal.keras\")\n",
    "metrics=pd.DataFrame([{\"accuracy\":float(acc),\"precision\":float(prec),\"recall\":float(rec),\"f1\":float(f1),\"roc_auc\":float(auc)}])\n",
    "metrics.to_csv(\"/content/metrics_minimal.csv\", index=False)\n",
    "\n",
    "print(\"Guardados:\")\n",
    "!ls -lh /content | grep -E \"minimal\\.keras|metrics_minimal\\.csv\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cabb4df4",
   "metadata": {},
   "source": [
    "\n",
    "## 8) (Opcional) Subir a GitHub\n",
    "- Crea un **PAT** (Personal Access Token) con `contents: write`.\n",
    "- Cambia `USUARIO`, `REPO` y (si aplica) `RAMA`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3849f1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Descomenta para usar (opcional)\n",
    "# !git config --global user.name \"Tu Nombre\"\n",
    "# !git config --global user.email \"[email protected]\"\n",
    "# REPO_URL=\"https://github.com/USUARIO/REPO.git\"  # <- cambia\n",
    "# !git clone $REPO_URL\n",
    "# %cd REPO\n",
    "# # Copiar el notebook manualmente (desde Archivo ‚Üí Descargar .ipynb) o ajustar ruta si ya conoces el nombre\n",
    "# # !cp \"/content/NombreDeTuNotebook.ipynb\" .\n",
    "# !cp /content/metrics_minimal.csv .\n",
    "# !cp /content/model_minimal.keras .  # opcional por tama√±o\n",
    "# with open(\".gitignore\",\"a\") as f: f.write(\"\\nchest_xray/\\n*.zip\\n*.keras\\n\")\n",
    "# import getpass, os\n",
    "# os.environ[\"GH_TOKEN\"]=getpass.getpass(\"Pega tu GitHub PAT (contents:write): \")\n",
    "# !git remote set-url origin https://${GH_TOKEN}@github.com/USUARIO/REPO.git\n",
    "# !git add . && git commit -m \"Proyecto minimal: RX t√≥rax con EfficientNetB0\" && git push origin HEAD:main\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
